{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random            \n",
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "import pandas as pd                                 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "from collections import defaultdict\n",
    "from datetime import timedelta\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bi_LSTM_AutoEncoder(nn.Module):\n",
    "    def __init__(self,in_size, hidden_layers, encode=12, num_layers=3):\n",
    "        super(Bi_LSTM_AutoEncoder, self).__init__()\n",
    "        self.encoderlstm = nn.LSTM(in_size, hidden_layers, num_layers=num_layers, bidirectional=True)\n",
    "        self.encoderlinear = nn.Linear(2*hidden_layers, encode)\n",
    "        \n",
    "        self.decoderlstm = nn.LSTM(encode, hidden_layers, num_layers=num_layers, bidirectional=True)\n",
    "        self.decoderlinear = nn.Linear(2*hidden_layers, in_size)\n",
    "    def forward(self, x):\n",
    "        encoded, _ = self.encoderlstm(x)\n",
    "        encoded = self.encoderlinear(encoded)\n",
    "        decoded, _ = self.decoderlstm(encoded)\n",
    "        decoded = self.decoderlinear(decoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super(Loader, self).__init__()\n",
    "        self.dataset = ''\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset.iloc[idx]\n",
    "        row = row.drop(labels={'label'})\n",
    "        data = torch.reshape(torch.from_numpy(np.array(row)/255).float(),(28,28))\n",
    "        return data\n",
    "    \n",
    "class Train_Loader(Loader):\n",
    "    def __init__(self):\n",
    "        super(Train_Loader, self).__init__()\n",
    "        self.dataset = pd.read_csv(\n",
    "                       'mnist_train.csv',\n",
    "                       index_col=False\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 1e-2         # learning rate\n",
    "w_d = 1e-5        # weight decay\n",
    "momentum = 0.9   \n",
    "epochs = 15\n",
    "\n",
    "train_set = Train_Loader()\n",
    "train_ = torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = defaultdict(list)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model= Bi_LSTM_AutoEncoder(28, 256)\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=w_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-b14e84588e70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "start = time.time()\n",
    "print('starting training')\n",
    "for epoch in range(epochs):\n",
    "    ep_start = time.time()\n",
    "    running_loss = 0.0\n",
    "    for bx, data in enumerate(train_):\n",
    "        data = data.to(device)\n",
    "        #print(data.shape)\n",
    "        sample = model(data)\n",
    "        loss = criterion(data, sample)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    epoch_loss = running_loss/len(train_set)\n",
    "    metrics['train_loss'].append(epoch_loss)\n",
    "    ep_end = time.time()\n",
    "    print('-----------------------------------------------')\n",
    "    print('[EPOCH] {}/{}\\n[LOSS] {}'.format(epoch+1,epochs,epoch_loss))\n",
    "    print('Epoch Complete in {}'.format(timedelta(seconds=ep_end-ep_start)))\n",
    "end = time.time()\n",
    "print('-----------------------------------------------')\n",
    "print('[System Complete: {}]'.format(timedelta(seconds=end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xa188437c50>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train loss\n",
    "_, ax = plt.subplots(1,1,figsize=(15,10))\n",
    "ax.set_title('Loss')\n",
    "ax.plot(metrics['train_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get threshold\n",
    "model.eval()\n",
    "loss_dist = []\n",
    "anom = pd.read_csv('data/abnormal.csv', index_col=[0])\n",
    "\n",
    "for i in range(len(anom)):\n",
    "    data = torch.from_numpy(np.array(anom.iloc[i][1:])/255).float()\n",
    "    sample = model(data.to(device))\n",
    "    loss = criterion(data.to(device), sample)\n",
    "    loss_dist.append(loss.item())\n",
    "\n",
    "loss_sc = []\n",
    "for i in loss_dist:\n",
    "    loss_sc.append((i,i))\n",
    "plt.scatter(*zip(*loss_sc))\n",
    "plt.axvline(0.3, 0.0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot threshold\n",
    "lower_threshold = 0.0\n",
    "upper_threshold = 0.3\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Loss Distribution')\n",
    "sns.distplot(loss_dist,bins=100,kde=True, color='blue')\n",
    "plt.axvline(upper_threshold, 0.0, 10, color='r')\n",
    "plt.axvline(lower_threshold, 0.0, 10, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "df = pd.read_csv('data/anom.csv', index_col=[0])\n",
    "ddf = pd.DataFrame(columns=df.columns)\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "total_anom = 0\n",
    "for i in range(len(loss_dist)):\n",
    "    total_anom += df.iloc[i]['label']\n",
    "    if loss_dist[i] >= upper_threshold:\n",
    "        n_df = pd.DataFrame([df.iloc[i]])\n",
    "        n_df['loss'] = loss_dist[i]\n",
    "        ddf = pd.concat([df,n_df], sort = True)\n",
    "        if float(df.iloc[i]['label']) == 1.0:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    else:\n",
    "        if float(df.iloc[i]['label']) == 1.0:\n",
    "            fn += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "print('[TP] {}\\t[FP] {}\\t[MISSED] {}'.format(tp, fp, total_anom-tp))\n",
    "print('[TN] {}\\t[FN] {}'.format(tn, fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = np.array([[tn,fp],[fn,tp]])\n",
    "plt.figure()\n",
    "sns.heatmap(conf,annot=True,annot_kws={\"size\": 16},fmt='g')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
